{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective Hyperparameter Optimization for Breast Cancer Classification\n",
    "\n",
    "## Tutorial: Step-by-Step Guide\n",
    "\n",
    "This notebook demonstrates how to use the implementation for multi-objective hyperparameter optimization of CNNs for breast cancer classification under dataset shift.\n",
    "\n",
    "**Datasets:**\n",
    "- **VinDr-Mammo** (Source): Training and validation\n",
    "- **INbreast** (Target): Zero-shot evaluation only\n",
    "\n",
    "**Objectives:**\n",
    "1. Maximize PR-AUC\n",
    "2. Maximize AUROC\n",
    "3. Minimize Brier score\n",
    "4. Minimize robustness degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Setup and Imports\n",
    "\n",
    "First, ensure all dependencies are installed and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Check CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Configuration\n",
    "\n",
    "Configure dataset paths and settings. **Adjust these to match your data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "# Set your dataset paths\n",
    "config.VINDR_MAMMO_PATH = \"/path/to/vindr_mammo\"  # TODO: Update this!\n",
    "config.INBREAST_PATH = \"/path/to/inbreast\"        # TODO: Update this!\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"VinDr-Mammo path: {config.VINDR_MAMMO_PATH}\")\n",
    "print(f\"  Exists: {os.path.exists(config.VINDR_MAMMO_PATH)}\")\n",
    "print(f\"\\nINbreast path: {config.INBREAST_PATH}\")\n",
    "print(f\"  Exists: {os.path.exists(config.INBREAST_PATH)}\")\n",
    "\n",
    "# Display current configuration\n",
    "print(\"\\n=== VinDr-Mammo Configuration ===\")\n",
    "for key, value in config.VINDR_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n=== INbreast Configuration ===\")\n",
    "for key, value in config.INBREAST_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Load and Parse VinDr-Mammo Dataset\n",
    "\n",
    "Use the dataset-specific parser to load VinDr-Mammo metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.parsers import parse_dataset\n",
    "from optimization.nsga3_runner import load_metadata\n",
    "\n",
    "# Load VinDr-Mammo metadata\n",
    "print(\"Loading VinDr-Mammo dataset...\")\n",
    "vindr_metadata = load_metadata(\n",
    "    dataset_name=\"vindr\",\n",
    "    dataset_path=config.VINDR_MAMMO_PATH,\n",
    "    dataset_config=config.VINDR_CONFIG\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded {len(vindr_metadata)} images\")\n",
    "print(f\"Unique patients: {vindr_metadata['patient_id'].nunique()}\")\n",
    "print(f\"Unique breasts: {vindr_metadata['breast_id'].nunique()}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample metadata:\")\n",
    "vindr_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distribution\n",
    "label_counts = vindr_metadata['label'].value_counts()\n",
    "print(\"\\n=== Label Distribution ===\")\n",
    "print(f\"Benign (0): {label_counts.get(0, 0)} ({label_counts.get(0, 0)/len(vindr_metadata)*100:.1f}%)\")\n",
    "print(f\"Malignant (1): {label_counts.get(1, 0)} ({label_counts.get(1, 0)/len(vindr_metadata)*100:.1f}%)\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Benign (0)', 'Malignant (1)'], rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "view_counts = vindr_metadata['view'].value_counts()\n",
    "view_counts.plot(kind='bar')\n",
    "plt.title('View Distribution')\n",
    "plt.xlabel('View')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Create Train/Validation Split\n",
    "\n",
    "Patient-wise split (80/20) to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import create_train_val_split\n",
    "from utils.seed import set_all_seeds\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_all_seeds(config.RANDOM_SEED)\n",
    "\n",
    "# Create patient-wise split\n",
    "train_metadata, val_metadata = create_train_val_split(\n",
    "    vindr_metadata,\n",
    "    train_ratio=config.TRAIN_VAL_SPLIT,\n",
    "    random_seed=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"=== Train/Validation Split ===\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Images: {len(train_metadata)}\")\n",
    "print(f\"  Patients: {train_metadata['patient_id'].nunique()}\")\n",
    "print(f\"  Breasts: {train_metadata['breast_id'].nunique()}\")\n",
    "print(f\"  Label 0: {(train_metadata['label'] == 0).sum()}\")\n",
    "print(f\"  Label 1: {(train_metadata['label'] == 1).sum()}\")\n",
    "\n",
    "print(f\"\\nValidation set:\")\n",
    "print(f\"  Images: {len(val_metadata)}\")\n",
    "print(f\"  Patients: {val_metadata['patient_id'].nunique()}\")\n",
    "print(f\"  Breasts: {val_metadata['breast_id'].nunique()}\")\n",
    "print(f\"  Label 0: {(val_metadata['label'] == 0).sum()}\")\n",
    "print(f\"  Label 1: {(val_metadata['label'] == 1).sum()}\")\n",
    "\n",
    "# Verify no patient overlap\n",
    "train_patients = set(train_metadata['patient_id'])\n",
    "val_patients = set(val_metadata['patient_id'])\n",
    "overlap = train_patients & val_patients\n",
    "print(f\"\\nPatient overlap: {len(overlap)} (should be 0)\")\n",
    "assert len(overlap) == 0, \"ERROR: Patient overlap detected!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Load and Inspect Sample Images\n",
    "\n",
    "Verify that images can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Load a few sample images\n",
    "image_dir = Path(config.VINDR_MAMMO_PATH) / config.VINDR_CONFIG[\"image_dir\"]\n",
    "\n",
    "sample_images = train_metadata.sample(min(4, len(train_metadata)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (_, row) in enumerate(sample_images.iterrows()):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    \n",
    "    img_path = image_dir / row['image_path']\n",
    "    \n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(\n",
    "            f\"Patient: {row['patient_id']}\\n\"\n",
    "            f\"View: {row['view']}, Label: {row['label']} \"\n",
    "            f\"({'Benign' if row['label'] == 0 else 'Malignant'})\"\n",
    "        )\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f\"Image not found:\\n{img_path}\", \n",
    "                      ha='center', va='center')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Create Model and DataLoaders\n",
    "\n",
    "Set up ResNet-50 model with partial fine-tuning and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNet50WithPartialFineTuning\n",
    "from data.dataset import create_dataloaders\n",
    "\n",
    "# Example hyperparameters\n",
    "hparams = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"augmentation_strength\": 0.5,\n",
    "    \"unfreeze_fraction\": 0.3,\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = ResNet50WithPartialFineTuning(\n",
    "    unfreeze_fraction=hparams[\"unfreeze_fraction\"],\n",
    "    dropout_rate=hparams[\"dropout_rate\"],\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "trainable_params = model.get_trainable_params()\n",
    "frozen_params = model.get_frozen_params()\n",
    "total_params = trainable_params + frozen_params\n",
    "\n",
    "print(\"=== Model Configuration ===\")\n",
    "print(f\"Architecture: ResNet-50\")\n",
    "print(f\"Pretrained: ImageNet\")\n",
    "print(f\"Unfreeze fraction: {hparams['unfreeze_fraction']:.2f}\")\n",
    "print(f\"Dropout rate: {hparams['dropout_rate']:.2f}\")\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "print(f\"  Frozen: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_metadata=train_metadata,\n",
    "    val_metadata=val_metadata,\n",
    "    image_dir=str(image_dir),\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    augmentation_strength=hparams[\"augmentation_strength\"],\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "print(f\"\\n=== DataLoaders ===\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"Augmentation strength: {hparams['augmentation_strength']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Train a Single Model (Demo)\n",
    "\n",
    "Train one model to demonstrate the pipeline. For full optimization, use `nsga3_runner.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.trainer import Trainer\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    val_metadata=val_metadata,\n",
    "    learning_rate=hparams[\"learning_rate\"],\n",
    "    weight_decay=hparams[\"weight_decay\"],\n",
    "    max_epochs=5,  # Use 5 epochs for demo (change to 100 for real training)\n",
    "    device=device,\n",
    "    checkpoint_dir=\"./demo_checkpoints\",\n",
    ")\n",
    "\n",
    "print(\"=== Training Configuration ===\")\n",
    "print(f\"Max epochs: 5 (demo)\")\n",
    "print(f\"Learning rate: {hparams['learning_rate']:.6f}\")\n",
    "print(f\"Weight decay: {hparams['weight_decay']:.6f}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"\\nStarting training...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "best_metrics = trainer.train()\n",
    "\n",
    "print(\"\\n=== Training Complete ===\")\n",
    "print(f\"Best validation metrics:\")\n",
    "print(f\"  PR-AUC: {best_metrics['pr_auc']:.4f}\")\n",
    "print(f\"  AUROC: {best_metrics['auroc']:.4f}\")\n",
    "print(f\"  Brier: {best_metrics['brier']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(trainer.history['train_loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(trainer.history['val_pr_auc'], label='PR-AUC')\n",
    "plt.plot(trainer.history['val_auroc'], label='AUROC')\n",
    "plt.title('Validation Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(trainer.history['val_brier'])\n",
    "plt.title('Validation Brier Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Brier Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Evaluate Robustness\n",
    "\n",
    "Measure performance degradation under intensity perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.robustness import RobustnessEvaluator\n",
    "\n",
    "# Evaluate robustness\n",
    "robustness_eval = RobustnessEvaluator(\n",
    "    model=model,\n",
    "    val_loader=val_loader,\n",
    "    val_metadata=val_metadata,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "robustness_degradation = robustness_eval.evaluate()\n",
    "\n",
    "print(\"=== Robustness Evaluation ===\")\n",
    "print(f\"Robustness degradation: {robustness_degradation:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - Lower is better (more robust)\")\n",
    "print(f\"  - Degradation = PR-AUC_standard - PR-AUC_perturbed\")\n",
    "print(f\"  - Negative value means model improved under perturbation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9: Compute All Objectives\n",
    "\n",
    "Calculate the 4 optimization objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all objectives\n",
    "objectives = {\n",
    "    \"PR-AUC\": best_metrics['pr_auc'],\n",
    "    \"AUROC\": best_metrics['auroc'],\n",
    "    \"Brier Score\": best_metrics['brier'],\n",
    "    \"Robustness Degradation\": robustness_degradation,\n",
    "}\n",
    "\n",
    "print(\"=== All Objectives ===\")\n",
    "for name, value in objectives.items():\n",
    "    direction = \"↑ (maximize)\" if \"AUC\" in name else \"↓ (minimize)\"\n",
    "    print(f\"{name:25s}: {value:7.4f} {direction}\")\n",
    "\n",
    "# For NSGA-III (all minimization)\n",
    "nsga3_objectives = [\n",
    "    -objectives[\"PR-AUC\"],\n",
    "    -objectives[\"AUROC\"],\n",
    "    objectives[\"Brier Score\"],\n",
    "    objectives[\"Robustness Degradation\"],\n",
    "]\n",
    "\n",
    "print(\"\\n=== Converted for NSGA-III (all minimization) ===\")\n",
    "print(f\"Objective vector: {nsga3_objectives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 10: Test Noisy OR Aggregation\n",
    "\n",
    "Verify breast-level aggregation from image-level predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.noisy_or import noisy_or_aggregation, aggregate_to_breast_level\n",
    "\n",
    "# Example: Manual Noisy OR\n",
    "p_cc = 0.3\n",
    "p_mlo = 0.4\n",
    "p_breast = noisy_or_aggregation(p_cc, p_mlo)\n",
    "\n",
    "print(\"=== Noisy OR Example ===\")\n",
    "print(f\"CC view probability: {p_cc:.3f}\")\n",
    "print(f\"MLO view probability: {p_mlo:.3f}\")\n",
    "print(f\"Breast-level probability: {p_breast:.3f}\")\n",
    "print(f\"\\nFormula: 1 - (1 - {p_cc}) * (1 - {p_mlo}) = {p_breast:.3f}\")\n",
    "\n",
    "# Test with validation set\n",
    "model.eval()\n",
    "image_predictions = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, image_ids in val_loader:\n",
    "        images = images.to(device)\n",
    "        preds = model(images).cpu().numpy()\n",
    "        for img_id, pred in zip(image_ids, preds):\n",
    "            image_predictions[img_id] = float(pred)\n",
    "\n",
    "breast_preds, breast_labels = aggregate_to_breast_level(\n",
    "    image_predictions, val_metadata\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Aggregation Results ===\")\n",
    "print(f\"Image-level predictions: {len(image_predictions)}\")\n",
    "print(f\"Breast-level predictions: {len(breast_preds)}\")\n",
    "print(f\"Reduction factor: {len(image_predictions) / len(breast_preds):.1f}x\")\n",
    "\n",
    "# Show sample breast with both views\n",
    "sample_breast = val_metadata.groupby('breast_id').filter(lambda x: len(x) == 2).groupby('breast_id').first()\n",
    "if len(sample_breast) > 0:\n",
    "    breast_id = sample_breast.index[0]\n",
    "    breast_images = val_metadata[val_metadata['breast_id'] == breast_id]\n",
    "    \n",
    "    print(f\"\\nSample breast: {breast_id}\")\n",
    "    for _, row in breast_images.iterrows():\n",
    "        pred = image_predictions.get(row['image_id'], 0.0)\n",
    "        print(f\"  {row['view']:3s} view: p = {pred:.3f}\")\n",
    "    \n",
    "    # Find aggregated prediction\n",
    "    breast_idx = val_metadata[val_metadata['breast_id'] == breast_id].index[0]\n",
    "    breast_dict = dict(zip(val_metadata['breast_id'], range(len(val_metadata['breast_id'].unique()))))\n",
    "    print(f\"  Breast-level (Noisy OR): p = {breast_preds[breast_dict.get(breast_id, 0)]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 11: Run NSGA-III Optimization (Full Pipeline)\n",
    "\n",
    "For full multi-objective optimization, run the NSGA-III script from command line.\n",
    "\n",
    "**Note:** This is computationally expensive! Each evaluation trains a full CNN.\n",
    "\n",
    "```bash\n",
    "# From terminal:\n",
    "python optimization/nsga3_runner.py\n",
    "```\n",
    "\n",
    "Configuration in `config.py`:\n",
    "```python\n",
    "NSGA3_CONFIG = {\n",
    "    \"pop_size\": 24,        # Population size\n",
    "    \"n_generations\": 50,   # Number of generations\n",
    "    \"n_objectives\": 4,     # 4 objectives\n",
    "}\n",
    "```\n",
    "\n",
    "**Total evaluations:** 24 × 50 = 1,200 (adjust for your compute budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimization configuration\n",
    "print(\"=== NSGA-III Configuration ===\")\n",
    "print(f\"Population size: {config.NSGA3_CONFIG['pop_size']}\")\n",
    "print(f\"Generations: {config.NSGA3_CONFIG['n_generations']}\")\n",
    "print(f\"Objectives: {config.NSGA3_CONFIG['n_objectives']}\")\n",
    "print(f\"\\nTotal evaluations: {config.NSGA3_CONFIG['pop_size'] * config.NSGA3_CONFIG['n_generations']}\")\n",
    "print(f\"\\nEstimated time (assuming 1 hour per evaluation):\")\n",
    "print(f\"  {config.NSGA3_CONFIG['pop_size'] * config.NSGA3_CONFIG['n_generations']} hours\")\n",
    "print(f\"  = {config.NSGA3_CONFIG['pop_size'] * config.NSGA3_CONFIG['n_generations'] / 24:.1f} days\")\n",
    "print(f\"\\n⚠️  Consider reducing pop_size and n_generations for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 12: Analyze Pareto Front (After Optimization)\n",
    "\n",
    "After NSGA-III completes, analyze the Pareto front.\n",
    "\n",
    "```bash\n",
    "# From terminal:\n",
    "python optimization/analyze_pareto.py --results_dir ./optimization_results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and analyze Pareto results (if available)\n",
    "import glob\n",
    "\n",
    "results_dir = \"./optimization_results\"\n",
    "\n",
    "# Find most recent results\n",
    "csv_files = glob.glob(f\"{results_dir}/pareto_solutions_*.csv\")\n",
    "\n",
    "if csv_files:\n",
    "    csv_files.sort(reverse=True)\n",
    "    latest_results = csv_files[0]\n",
    "    \n",
    "    print(f\"Loading Pareto solutions from: {latest_results}\")\n",
    "    pareto_df = pd.read_csv(latest_results)\n",
    "    \n",
    "    print(f\"\\nNumber of Pareto solutions: {len(pareto_df)}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n=== Pareto Front Summary ===\")\n",
    "    print(pareto_df[['pr_auc', 'auroc', 'brier', 'robustness_degradation']].describe())\n",
    "    \n",
    "    # Find extreme solutions\n",
    "    print(\"\\n=== Extreme Solutions ===\")\n",
    "    print(f\"\\nBest PR-AUC: {pareto_df.loc[pareto_df['pr_auc'].idxmax()]['pr_auc']:.4f}\")\n",
    "    print(f\"Best AUROC: {pareto_df.loc[pareto_df['auroc'].idxmax()]['auroc']:.4f}\")\n",
    "    print(f\"Best Brier: {pareto_df.loc[pareto_df['brier'].idxmin()]['brier']:.4f}\")\n",
    "    print(f\"Best Robustness: {pareto_df.loc[pareto_df['robustness_degradation'].idxmin()]['robustness_degradation']:.4f}\")\n",
    "    \n",
    "    # Plot Pareto front (2D projections)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    pairs = [\n",
    "        ('pr_auc', 'auroc'),\n",
    "        ('pr_auc', 'brier'),\n",
    "        ('pr_auc', 'robustness_degradation'),\n",
    "        ('auroc', 'brier'),\n",
    "        ('auroc', 'robustness_degradation'),\n",
    "        ('brier', 'robustness_degradation'),\n",
    "    ]\n",
    "    \n",
    "    for idx, (obj1, obj2) in enumerate(pairs):\n",
    "        axes[idx].scatter(pareto_df[obj1], pareto_df[obj2], alpha=0.6)\n",
    "        axes[idx].set_xlabel(obj1.replace('_', ' ').title())\n",
    "        axes[idx].set_ylabel(obj2.replace('_', ' ').title())\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No Pareto results found.\")\n",
    "    print(\"Run 'python optimization/nsga3_runner.py' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 13: Evaluate on INbreast (Zero-Shot Transfer)\n",
    "\n",
    "Load INbreast and evaluate trained model without any fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load INbreast dataset\n",
    "print(\"Loading INbreast dataset...\")\n",
    "inbreast_metadata = load_metadata(\n",
    "    dataset_name=\"inbreast\",\n",
    "    dataset_path=config.INBREAST_PATH,\n",
    "    dataset_config=config.INBREAST_CONFIG\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded {len(inbreast_metadata)} images\")\n",
    "print(f\"Unique patients: {inbreast_metadata['patient_id'].nunique()}\")\n",
    "print(f\"Unique breasts: {inbreast_metadata['breast_id'].nunique()}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample metadata:\")\n",
    "inbreast_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distribution\n",
    "label_counts = inbreast_metadata['label'].value_counts()\n",
    "print(\"\\n=== INbreast Label Distribution ===\")\n",
    "print(f\"Benign (0): {label_counts.get(0, 0)} ({label_counts.get(0, 0)/len(inbreast_metadata)*100:.1f}%)\")\n",
    "print(f\"Malignant (1): {label_counts.get(1, 0)} ({label_counts.get(1, 0)/len(inbreast_metadata)*100:.1f}%)\")\n",
    "\n",
    "# Check BI-RADS distribution (including subcategories)\n",
    "print(\"\\n=== BI-RADS Distribution (with subcategories) ===\")\n",
    "birads_counts = inbreast_metadata['birads_original'].value_counts()\n",
    "for birads, count in birads_counts.items():\n",
    "    label = inbreast_metadata[inbreast_metadata['birads_original'] == birads]['label'].iloc[0]\n",
    "    print(f\"  {birads}: {count} images → Label {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluate_target import evaluate_target_zero_shot\n",
    "from training.metrics import find_optimal_threshold\n",
    "\n",
    "# Find optimal threshold on source validation set\n",
    "threshold = find_optimal_threshold(breast_preds, breast_labels)\n",
    "print(f\"Optimal threshold (from source): {threshold:.4f}\")\n",
    "\n",
    "# Get INbreast image directory\n",
    "inbreast_image_dir = str(Path(config.INBREAST_PATH) / config.INBREAST_CONFIG[\"image_dir\"])\n",
    "\n",
    "# Zero-shot evaluation\n",
    "print(\"\\n=== Zero-Shot Evaluation on INbreast ===\")\n",
    "print(\"NOTE: No fine-tuning, no threshold tuning - pure transfer!\\n\")\n",
    "\n",
    "target_metrics = evaluate_target_zero_shot(\n",
    "    model=model,\n",
    "    target_metadata=inbreast_metadata,\n",
    "    image_dir=inbreast_image_dir,\n",
    "    threshold=threshold,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"\\n=== INbreast Results ===\")\n",
    "print(f\"PR-AUC: {target_metrics['pr_auc']:.4f}\")\n",
    "print(f\"AUROC: {target_metrics['auroc']:.4f}\")\n",
    "print(f\"Brier Score: {target_metrics['brier']:.4f}\")\n",
    "print(f\"Threshold (transferred): {threshold:.4f}\")\n",
    "print(f\"Sensitivity: {target_metrics['sensitivity']:.4f}\")\n",
    "print(f\"Specificity: {target_metrics['specificity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare source and target performance\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['PR-AUC', 'AUROC', 'Brier Score'],\n",
    "    'VinDr-Mammo (Source)': [best_metrics['pr_auc'], best_metrics['auroc'], best_metrics['brier']],\n",
    "    'INbreast (Target)': [target_metrics['pr_auc'], target_metrics['auroc'], target_metrics['brier']],\n",
    "})\n",
    "\n",
    "comparison['Difference'] = comparison['INbreast (Target)'] - comparison['VinDr-Mammo (Source)']\n",
    "\n",
    "print(\"\\n=== Source vs Target Comparison ===\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison['VinDr-Mammo (Source)'], width, label='VinDr-Mammo (Source)', alpha=0.8)\n",
    "ax.bar(x + width/2, comparison['INbreast (Target)'], width, label='INbreast (Target)', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Metric')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Source vs Target Performance (Zero-Shot Transfer)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison['Metric'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **Dataset loading** with dataset-specific parsers (VinDr-Mammo, INbreast)\n",
    "2. ✅ **BI-RADS mapping** including subcategories (4A, 4B, 4C)\n",
    "3. ✅ **Patient-wise splitting** (no data leakage)\n",
    "4. ✅ **Model creation** (ResNet-50 with partial fine-tuning)\n",
    "5. ✅ **Training** with early stopping\n",
    "6. ✅ **Robustness evaluation** under perturbations\n",
    "7. ✅ **Noisy OR aggregation** for breast-level predictions\n",
    "8. ✅ **4 objectives** (PR-AUC, AUROC, Brier, Robustness)\n",
    "9. ✅ **Zero-shot transfer** to INbreast\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "For full multi-objective optimization:\n",
    "\n",
    "```bash\n",
    "# Run NSGA-III\n",
    "python optimization/nsga3_runner.py\n",
    "\n",
    "# Analyze Pareto front\n",
    "python optimization/analyze_pareto.py\n",
    "\n",
    "# Evaluate selected solutions\n",
    "python evaluation/evaluate_source.py --checkpoint path/to/checkpoint.pt --hyperparameters config.json\n",
    "python evaluation/evaluate_target.py --checkpoint path/to/checkpoint.pt --threshold 0.45 --hyperparameters config.json\n",
    "```\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- **[README.md](README.md)** - Main documentation\n",
    "- **[DATASET_SETUP_GUIDE.md](DATASET_SETUP_GUIDE.md)** - Dataset preparation\n",
    "- **[IMPLEMENTATION_NOTES.md](IMPLEMENTATION_NOTES.md)** - Technical details\n",
    "- **[TEST_RESULTS.md](TEST_RESULTS.md)** - Test documentation\n",
    "\n",
    "### Testing\n",
    "\n",
    "```bash\n",
    "python test_correctness.py  # 79 tests\n",
    "python test_parsers.py      # 34 tests\n",
    "python test_integration.py  # 1 test\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
